---
title: Use cases
description: Dig into the common use cases for building on Hoku.
---

import { Cards, Card, Callout } from "nextra/components";

## AI & machine learning

Hoku's flexible data layer can power a variety of AI and machine learning workflows, from data storage and retrieval to
model training and inference. The full Hoku stack can be used in a modular fashion to build custom workflows, or the
"full stack" of Hoku data services can be used to power a fully decentralized pipeline.

For example, you might use Hoku to:

- Store large datasets in S3 compatible buckets and run an ML pipeline, writing the classification or sentiment analysis
  results to the object store.
- Store large models or checkpoints training states in buckets.
- Run an event streaming workflow with Ceramic streams, using the event store to power a compute job through a function
  when a new event is detected.
- Indexing data from the event pipeline with OrbisDB.

Check out the following tutorials for more ideas:

<Cards>
  <Card title="Basin" href="/tutorials/basin-ml" />
  <Card title="Ceramic" href="/tutorials/ceramic-user-data" />
  <Card title="OrbisDB" href="/tutorials/orbisdb-indexing" />
  <Card title="Hoku full stack" href="/tutorials/hoku-ml-pipeline" />
</Cards>

## DePIN networks

Hoku's native onchain access controls and privacy help write large scale data to the network while preserving the
privacy of individual data producers.

<Callout type="info">

This page is a work in progress.

</Callout>
